# Types of Agents

## Table-driven Agent
- Stores a precomputed table mapping all possible percept sequences to corresponding actions
- Highly inefficient for complex environments
- Simple implementation but impractical for real-world use

## Simple Reflex Agent
- Selects actions based only on current percept
- Ignores history of past percepts and actions
- Efficient but limited in handling dynamic environments
- Works well in fully observable environments

## Goal-based Agent
- Takes actions to achieve specific goals
- Considers future consequences of actions
- More flexible decision-making than reflex agents
- Can handle partially observable environments

## Utility-based Agent
- Evaluates actions based on utility function
- Maximizes performance through optimal decisions
- Handles uncertainty effectively
- More sophisticated than goal-based agents







